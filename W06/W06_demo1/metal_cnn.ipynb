{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN(卷積神經網路) 金屬表面分類\n",
    "\n",
    "- 金屬類型影像資料集    \n",
    "- https://ieee-dataport.org/open-access/data-set-various-metal-types\n",
    "- test data set\n",
    "- https://www.kaggle.com/datasets/fantacher/neu-metal-surface-defects-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 引入模組\n",
    "- 如果沒有此套件需要先執行指令安裝\n",
    "\n",
    "`!pip install imutils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten ,Conv2D, MaxPool2D \n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 匯入資料集  \n",
    "- imagePaths: 匯入資料集\n",
    "- IMAGE_DIMS = (20, 20, 3), 影像尺寸為20x20, 因為是RGB三色，所以x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = sorted(list(paths.list_images(\".\\\\Dataset\\\\CNN\\\\Variour_metal_types\\\\\")))\n",
    "\n",
    "IMAGE_DIMS = (20, 20, 3)\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 整理資料集\n",
    "- data: 資料集，存放由cv2.imread()讀檔，並把尺寸轉為我們定義的大小的圖檔資料\n",
    "- labels: 標籤，將圖片的類別放在labels中\n",
    "- 如果未來需要新增資料集類別，可以新增or修改類別資料夾，擴充你要的資料類型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    # extract set of class labels from the image path and update the\n",
    "    # labels list\n",
    "    # l = label = imagePath.split(os.path.sep)[-2]\n",
    "    if imagePath.split(os.path.sep)[-2] == 'iron':\n",
    "        l = 0\n",
    "    elif imagePath.split(os.path.sep)[-2] == 'copper':\n",
    "        l = 1\n",
    "    labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data[0]))\n",
    "print(len(data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 整理資料集格式  \n",
    "- Data: 存放轉為nparray的資料\n",
    "- Label: 存放轉為nparray的資料\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.array(data, dtype=\"float\")\n",
    "Label = np.array(labels)\n",
    "\n",
    "print(\"Data shape:\" + str(Data.shape))\n",
    "print(\"Label shape:\" + str(Label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.將資料分為train、test資料集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Data, Label, test_size=0.2, random_state=0, stratify=Label)\n",
    "\n",
    "# 訓練資料筆數與維度大小\n",
    "print(\"Training data shape:\" + str(x_train.shape))\n",
    "print(\"Training label shape:\" + str(y_train.shape))\n",
    "# 測試資料筆數與維度大小\n",
    "print(\"Test data shape:\" + str(x_test.shape))\n",
    "print(\"Test label shape:\" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Label前處理，轉為onehot的格式\n",
    "- labels內容進行one-hot encoding，才符合Keras所要求的資料結構。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = to_categorical(y_train)\n",
    "y_test_onehot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 建立CNN Model\n",
    "\n",
    "- model.add(Conv2D( )) 建立卷積層  \n",
    "    - filter = 16，代表輸出空間的維度大小(即為卷積中濾波器輸出數量)。  \n",
    "    - Kernel_size = (5, 5)，常為為(3,3)或是(5,5)\n",
    "    - padding = 'same'，代表卷積層取週邊kernel_size的滑動視窗時，若超越邊界時，一律補零處理\n",
    "    - input_shape=(28,28,1)代表圖片尺寸為28*28且為黑白。(28,28,3)代表尺寸為28*28且為三色\n",
    "  \n",
    "- model.add(MaxPool2D( )) 建立池化層  \n",
    "    - pool_size = (2,2)，池化層視窗的大小\n",
    "    \n",
    "- model.add(Dropout())  \n",
    "    - 使用Dropout防止過度擬合，每次訓練時拿走固定比例的神經元。  \n",
    "\n",
    "- model.add(Flatten( )) 建立平坦層  \n",
    "    \n",
    "- model.add(Dense(128)) 建立隱藏層(密集層)\n",
    "    - 128個神經元\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  \n",
    "# 建立卷積層   \n",
    "model.add(Conv2D(filters=16,  \n",
    "                 kernel_size=(5,5),  \n",
    "                 padding='same',  \n",
    "                 input_shape=IMAGE_DIMS,\n",
    "                 activation='relu')) \n",
    "# 建立池化層 \n",
    "model.add(MaxPool2D(pool_size=(2,2)))  \n",
    "  \n",
    "# 建立卷積層 \n",
    "model.add(Conv2D(filters=32,  \n",
    "                 kernel_size=(5,5),  \n",
    "                 padding='same',  \n",
    "                 activation='relu'))   \n",
    "\n",
    "# 建立池化層 \n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# 建立Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# 建立平坦層\n",
    "model.add(Flatten())\n",
    "# 建立隱藏層\n",
    "model.add(Dense(128, activation='relu'))  \n",
    "# 建立Dropout_2\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# 建立輸出層\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()  \n",
    "print(\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 定義訓練方式與訓練模型    \n",
    "\n",
    "- optimizer: 設定訓練時的優化方法，深度學習中使用'adam'可讓訓練更快收斂，並提高準確率。  \n",
    "- metrics: 設定評估模型的方法是'accuracy' (準確率)。  \n",
    "\n",
    "#### fit\n",
    "- validation_split = 0.2: 用於沒有提供驗證集時，將訓練資料集取出20%當作驗證資料集。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在訓練模型之前, 我們必須先使用 compile 方法\n",
    "# loss : 設定 loss function, 深度學習通常使用'cross_entropy'交叉熵訓練效果較好.\n",
    "# optimizer : 設定訓練時的優化方法，深度學習中使用'adam'可讓訓練更快收斂，並提高準確率\n",
    "# metrics : 設定評估模型的方式是 accuracy (準確率)\n",
    "# 定義訓練方式 \n",
    "# from tensorflow.keras.optimizers import Adam, SGD\n",
    "# adam = Adam(lr=0.0005)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "train_history = model.fit(x = x_train, \n",
    "                          y = y_train_onehot,\n",
    "                          validation_split=0.2,\n",
    "                          epochs=5, \n",
    "                          batch_size=50, \n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 儲存訓練好的模型 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立 show_train_history function 顯示訓練過程   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練步驟會將每一個訓練週期的 accuracy 與 loss 記錄在 train_history 變數. \n",
    "# 我們可以使用下面程式碼讀取 train_history 以圖表顯示訓練過程:\n",
    "import matplotlib.pyplot as plt  \n",
    "def show_train_history(train_history, train, validation):  \n",
    "    plt.plot(train_history.history[train])  \n",
    "    plt.plot(train_history.history[validation])  \n",
    "    plt.title('Train History')  \n",
    "    plt.ylabel(train)  \n",
    "    plt.xlabel('Epoch')  \n",
    "    plt.legend(['train', 'validation'], loc='upper left')  \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 圖表顯示 accuracy\n",
    "show_train_history(train_history, 'accuracy', 'val_accuracy')\n",
    "# 2. 圖表顯示 loss\n",
    "show_train_history(train_history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用測試資料評估模型準確率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test_onehot)  \n",
    "print(\" Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看10筆預測結果資料  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "def plot_images_labels_predict(images, labels, prediction, idx, num=10):  \n",
    "    fig = plt.gcf()  \n",
    "    fig.set_size_inches(12, 14)  \n",
    "    if num > 25: num = 25  \n",
    "    for i in range(0, num):  \n",
    "        ax=plt.subplot(5,5, 1+i)  \n",
    "        ax.imshow(images[idx] / 255, cmap='binary')  \n",
    "        title = \"l=\" + str(labels[idx])  \n",
    "        if len(prediction) > 0:  \n",
    "            title = \"l={},p={}\".format(str(labels[idx]), str(prediction[idx]))  \n",
    "        else:  \n",
    "            title = \"l={}\".format(str(labels[idx]))  \n",
    "        ax.set_title(title, fontsize=10)  \n",
    "        ax.set_xticks([]); ax.set_yticks([])  \n",
    "        idx+=1  \n",
    "    plt.show()  \n",
    "    \n",
    "print(\" Making prediction to x_Test_norm\")  \n",
    "#prediction = model.predict_classes(x_test)  # Making prediction and save result to prediction  \n",
    "predict_x=model.predict(x_test) \n",
    "prediction=np.argmax(predict_x,axis=1)\n",
    "\n",
    "\n",
    "print(\"\")   \n",
    "plot_images_labels_predict(x_test, y_test, prediction, idx=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
